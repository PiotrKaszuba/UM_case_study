{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\sebastian\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn import neighbors\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import dataPrepare as dp\n",
    "from FeatureEngineeringManualRun import getFeatures\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "from sklearn.metrics import classification_report\n",
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import logging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfx = dp.getData(200000)\n",
    "target = dp.target\n",
    "\n",
    "\n",
    "dfx = getFeatures(dfx)\n",
    "\n",
    "testDf = dp.getValidData(30000)\n",
    "testDf = getFeatures(testDf)\n",
    "df = dfx.drop(columns=dp.categorical_cols)\n",
    "features = list(df.columns)\n",
    "features.remove(dp.target)\n",
    "x_train = df[features]\n",
    "y_train = df[target]\n",
    "x_test = testDf[features]\n",
    "y_test = testDf[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Domyślne parametry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.0799            1.50m\n",
      "         2           0.0682            1.47m\n",
      "         3           0.0586            1.50m\n",
      "         4           0.0509            1.49m\n",
      "         5           0.0445            1.47m\n",
      "         6           0.0393            1.46m\n",
      "         7           0.0349            1.46m\n",
      "         8           0.0313            1.44m\n",
      "         9           0.0284            1.43m\n",
      "        10           0.0259            1.41m\n",
      "        20           0.0154            1.24m\n",
      "        30           0.0125            1.06m\n",
      "        40           0.0113           54.90s\n",
      "        50           0.0107           45.15s\n",
      "        60           0.0102           36.09s\n",
      "        70           0.0100           26.66s\n",
      "        80           0.0096           17.79s\n",
      "        90           0.0094            8.84s\n",
      "       100           0.0091            0.00s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "                          learning_rate=0.1, loss='ls', max_depth=3,\n",
       "                          max_features=None, max_leaf_nodes=None,\n",
       "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                          min_samples_leaf=1, min_samples_split=2,\n",
       "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                          n_iter_no_change=None, presort='auto',\n",
       "                          random_state=None, subsample=1.0, tol=0.0001,\n",
       "                          validation_fraction=0.1, verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GradientBoostingRegressor(verbose=1)\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE value  is: 0.06839241796654057\n",
      "RMSE value  is: 0.09685525539657987\n",
      "R2:  0.901131307151752\n"
     ]
    }
   ],
   "source": [
    "error_MAE = mean_absolute_error(y_test,y_pred) #calculate err\n",
    "print('MAE value  is:', error_MAE)\n",
    "error_RMSE = math.sqrt(mean_squared_error(y_test,y_pred)) #calculate err\n",
    "print('RMSE value  is:', error_RMSE)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print('R2: ', r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parametry wybrane metodą prób i błędów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.0799            2.94m\n",
      "         2           0.0682            3.14m\n",
      "         3           0.0586            3.23m\n",
      "         4           0.0509            3.24m\n",
      "         5           0.0445            3.22m\n",
      "         6           0.0393            3.16m\n",
      "         7           0.0349            3.05m\n",
      "         8           0.0313            2.95m\n",
      "         9           0.0284            2.91m\n",
      "        10           0.0259            2.89m\n",
      "        20           0.0154            2.76m\n",
      "        30           0.0125            2.59m\n",
      "        40           0.0113            2.39m\n",
      "        50           0.0107            2.18m\n",
      "        60           0.0102            2.06m\n",
      "        70           0.0100            1.86m\n",
      "        80           0.0096            1.71m\n",
      "        90           0.0094            1.56m\n",
      "       100           0.0091            1.40m\n",
      "       200           0.0080            0.00s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "                          learning_rate=0.1, loss='ls', max_depth=3,\n",
       "                          max_features=None, max_leaf_nodes=None,\n",
       "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                          min_samples_leaf=2, min_samples_split=2,\n",
       "                          min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "                          n_iter_no_change=None, presort='auto',\n",
       "                          random_state=None, subsample=1.0, tol=0.0001,\n",
       "                          validation_fraction=0.1, verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_1 = GradientBoostingRegressor(n_estimators=200,min_samples_leaf=2,max_depth=3,verbose=1)\n",
    "clf_1.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_1 = clf_1.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE value  is: 0.06458851237584845\n",
      "RMSE value  is: 0.09146371292670824\n",
      "R2:  0.9118321874966576\n"
     ]
    }
   ],
   "source": [
    "error_MAE_1 = mean_absolute_error(y_test,y_pred_1) #calculate err\n",
    "print('MAE value  is:', error_MAE)\n",
    "error_RMSE_1 = math.sqrt(mean_squared_error(y_test,y_pred_1)) #calculate err\n",
    "print('RMSE value  is:', error_RMSE)\n",
    "r2_1 = r2_score(y_test, y_pred_1)\n",
    "print('R2: ', r2_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parametry wybrane przy pomocy grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.0787           18.82m\n",
      "         2           0.0660           18.99m\n",
      "         3           0.0557           18.80m\n",
      "         4           0.0473           18.66m\n",
      "         5           0.0405           18.47m\n",
      "         6           0.0348           18.35m\n",
      "         7           0.0303           18.26m\n",
      "         8           0.0265           17.97m\n",
      "         9           0.0234           17.94m\n",
      "        10           0.0208           17.83m\n",
      "        20           0.0102           17.23m\n",
      "        30           0.0082           16.03m\n",
      "        40           0.0075           14.91m\n",
      "        50           0.0071           13.59m\n",
      "        60           0.0069           12.30m\n",
      "        70           0.0068           11.20m\n",
      "        80           0.0067           10.15m\n",
      "        90           0.0066            9.42m\n",
      "       100           0.0066            8.56m\n",
      "       200           0.0062            2.36m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "                          learning_rate=0.1, loss='ls', max_depth=7,\n",
       "                          max_features=None, max_leaf_nodes=None,\n",
       "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                          min_samples_leaf=100, min_samples_split=2,\n",
       "                          min_weight_fraction_leaf=0.0, n_estimators=250,\n",
       "                          n_iter_no_change=None, presort='auto',\n",
       "                          random_state=None, subsample=1.0, tol=0.0001,\n",
       "                          validation_fraction=0.1, verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_2 = GradientBoostingRegressor(n_estimators=250,min_samples_leaf=100,max_depth=7,verbose=1)\n",
    "clf_2.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_2 = clf_2.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE value  is: 0.05889381733698692\n",
      "RMSE value  is: 0.08404546743017213\n",
      "R2:  0.9255540622407681\n"
     ]
    }
   ],
   "source": [
    "error_MAE_2 = mean_absolute_error(y_test,y_pred_2) #calculate err\n",
    "print('MAE value  is:', error_MAE_2)\n",
    "error_RMSE_2 = math.sqrt(mean_squared_error(y_test,y_pred_2)) #calculate err\n",
    "print('RMSE value  is:', error_RMSE_2)\n",
    "r2_2 = r2_score(y_test, y_pred_2)\n",
    "print('R2: ', r2_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Strojenie parametrów"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zredukoawanie liczbości zbioru danych w celu osiagnięca rezultatów w sensownym czasie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tunning_x_train = x_train.head(20000)\n",
    "tunning_y_train = y_train.head(20000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensowniejsze było by wybranie losowe wybranie przykłądów z całego zbioru. (Obserwacja, po strojeniu parametrów nie wykonana ze względu na czas) \n",
    "\n",
    "(TODO: Dalsze rozwinięcie projektu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do strojenia wybraliśy tylko kilka parametrów:\n",
    "## 1. n_estimators \n",
    "Liczba drzew powstałych podczas nauki. Według dokumentacji zalecane są dość duże wartości. (Pokrywa się to z wynikami ponieżej)\n",
    "## 2. max_depth\n",
    "Maksymalna wysokość drzew powstałych podczas nauki. Zalecane jest ekspyrementowanie z wartością, w zależnośći od danych.\n",
    "## 3. min_samples_leaf\n",
    "Minimalna liczba przykłądów które muszą się, znaleźć węźle aby mógł być uznany za liść. Wysoka wartość może spowodować wygładzenie modelu szczególnie dla regresji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('clf', GradientBoostingRegressor()),\n",
    "])\n",
    "\n",
    "# add more parameters will give better exploring power but will\n",
    "# increase processing time in a combinatorial way\n",
    "parameters = {\n",
    "    #TUTAJ TWORZYMY LISTY PARAMETRÓW WEDŁUG WZORCA\n",
    "     #<nazwa zmiennej z pipeline>__<nazwa parametru>\n",
    "#     'clf__n_estimators': (100,200,250,300,400,500,600,700,800), # Wykorzystane dla MAE\n",
    "    'clf__n_estimators': (100,200,250,300,400), # Wykorzystane dla MSE\n",
    "    'clf__max_depth' :(1,2,3,5,7),\n",
    "    'clf__min_samples_leaf':(1,10,100,0.001,0.0001),\n",
    "#     'clf__max_features':('auto','sqrt','log2',None),\n",
    "\n",
    "    #Choosing max_features < n_features leads to a reduction of variance and an increase in bias.\n",
    "}\n",
    "\n",
    "# specify metrics\n",
    "scores = {\n",
    "#     'max_error': make_scorer(mean_absolute_error),\n",
    "#     'neg_mean_absolute_error': make_scorer(mean_absolute_error),\n",
    "    'neg_mean_squared_error': make_scorer(mean_squared_error),\n",
    "#     'neg_mean_squared_log_error': make_scorer(mean_squared_log_error),\n",
    "#     'neg_median_absolute_error': make_scorer(median_absolute_error),\n",
    "#     'r2': make_scorer(r2_score),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for neg_mean_squared_error\n",
      "\n",
      "Fitting 5 folds for each of 125 candidates, totalling 625 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    9.8s\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 418 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=-1)]: Done 625 out of 625 | elapsed: 16.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank: 1\n",
      "Mean validation score: -0.008 (std: 0.000)\n",
      "Parameters: {'clf__max_depth': 7, 'clf__min_samples_leaf': 100, 'clf__n_estimators': 250}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: -0.008 (std: 0.000)\n",
      "Parameters: {'clf__max_depth': 7, 'clf__min_samples_leaf': 100, 'clf__n_estimators': 200}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: -0.008 (std: 0.000)\n",
      "Parameters: {'clf__max_depth': 5, 'clf__min_samples_leaf': 100, 'clf__n_estimators': 400}\n",
      "\n",
      "Model with rank: 4\n",
      "Mean validation score: -0.008 (std: 0.000)\n",
      "Parameters: {'clf__max_depth': 7, 'clf__min_samples_leaf': 0.001, 'clf__n_estimators': 200}\n",
      "\n",
      "Model with rank: 5\n",
      "Mean validation score: -0.008 (std: 0.000)\n",
      "Parameters: {'clf__max_depth': 7, 'clf__min_samples_leaf': 100, 'clf__n_estimators': 300}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Poszukiwanie paramterów\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    grid_search = GridSearchCV(pipeline, parameters,\n",
    "                       scoring=score,n_jobs=-1, cv=5, verbose=1)\n",
    "    grid_search.fit(tunning_x_train, tunning_y_train)\n",
    "    report(grid_search.cv_results_, n_top=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UWAGA\n",
    "Ze względu na bład w funkcji drukujacej podczas strojenia parametrów. Wyniki strojenia parametrów zostały zaprezentowane poniżej. (Ze względu na oszczędność czasową. Dla zredukowanego zbioru danych szukanie wartośći parametrów metodą grid search trwa ponad 1h.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAE top 5 parameters configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank: 1\n",
      "Mean validation score: -0.063 (std: 0.001)\n",
      "Parameters: {'clf__max_depth': 7, 'clf__min_samples_leaf': 100, 'clf__n_estimators': 250}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: -0.063 (std: 0.001)\n",
      "Parameters: {'clf__max_depth': 7, 'clf__min_samples_leaf': 100, 'clf__n_estimators': 200}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: -0.063 (std: 0.001)\n",
      "Parameters: {'clf__max_depth': 7, 'clf__min_samples_leaf': 100, 'clf__n_estimators': 300}\n",
      "\n",
      "Model with rank: 4\n",
      "Mean validation score: -0.063 (std: 0.001)\n",
      "Parameters: {'clf__max_depth': 7, 'clf__min_samples_leaf': 0.001, 'clf__n_estimators': 200}\n",
      "\n",
      "Model with rank: 5\n",
      "Mean validation score: -0.063 (std: 0.001)\n",
      "Parameters: {'clf__max_depth': 5, 'clf__min_samples_leaf': 1, 'clf__n_estimators': 400}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report(grid_search.cv_results_, n_top=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MSE top 5 parameters configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank: 1\n",
      "Mean validation score: -0.008 (std: 0.000)\n",
      "Parameters: {'clf__max_depth': 7, 'clf__min_samples_leaf': 100, 'clf__n_estimators': 250}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: -0.008 (std: 0.000)\n",
      "Parameters: {'clf__max_depth': 7, 'clf__min_samples_leaf': 100, 'clf__n_estimators': 200}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: -0.008 (std: 0.000)\n",
      "Parameters: {'clf__max_depth': 5, 'clf__min_samples_leaf': 100, 'clf__n_estimators': 400}\n",
      "\n",
      "Model with rank: 4\n",
      "Mean validation score: -0.008 (std: 0.000)\n",
      "Parameters: {'clf__max_depth': 7, 'clf__min_samples_leaf': 0.001, 'clf__n_estimators': 200}\n",
      "\n",
      "Model with rank: 5\n",
      "Mean validation score: -0.008 (std: 0.000)\n",
      "Parameters: {'clf__max_depth': 7, 'clf__min_samples_leaf': 100, 'clf__n_estimators': 300}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report(grid_search.cv_results_, n_top=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOM SEARCH\n",
    "Te same parametry co poprzednio "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Z powodu niedoszacowania czasu nie otrzymano wiargodnych wyników.\n",
    "Ze wzgledu na wyskokie wartośći niektórych parametrów proces strojenia się wydłuża. W szczególnośći mowa tu o parametrze **n_estimators**. Po wykonaniu 100 iteracji nie udało się znaleść, żadnej kobinacji lepszej niż przy użyciu metody grid search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: ROZWINĄĆ W PRZYSZŁOŚCI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify parameters and distributions to sample from\n",
    "# add more parameters will give better exploring power but will\n",
    "# dicrease chance to find optimal combinadtion in constatnt number of itters\n",
    "# increase number of itets increase processing time in linear way\n",
    "param_dist = {\n",
    "                \"clf__n_estimators\": sp_randint(1, 2000),\n",
    "                'clf__max_depth' : sp_randint(1, 20),\n",
    "#                 \"clf__max_features\": ['auto','sqrt','log2',None],\n",
    "                \"clf__min_samples_leaf\": sp_randint(1, 1000),\n",
    "             }\n",
    "# random search iters number\n",
    "n_iter_search = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for score in scores:\n",
    "#     print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "#     random_search = RandomizedSearchCV(pipeline, param_distributions=param_dist,scoring=score,\n",
    "#                                        n_iter=n_iter_search, cv=5, n_jobs=8, verbose=1,iid=False)\n",
    "\n",
    "#     random_search.fit(tunning_x_train, tunning_y_train)\n",
    "#     report(random_search.cv_results_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
